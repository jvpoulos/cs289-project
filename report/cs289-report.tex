\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{booktabs}
\usepackage{cvpr}
\usepackage{graphicx}
\usepackage{color, colortbl}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{hyperref}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\thefootnote}{$\star$}

\cvprfinalcopy % *** Uncomment this line for the final submission

\usepackage{footmisc} % Daggers for author notes
\DefineFNsymbols{mySymbols}{{\ensuremath\dagger}{\ensuremath\ddagger}\S\P
   *{**}{\ensuremath{\dagger\dagger}}{\ensuremath{\ddagger\ddagger}}}
\setfnsymbol{mySymbols}

% Colors for highlighting tables
\definecolor{Gray}{gray}{0.9}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Methods for handling missing and categorical data for classification with neural
networks$^\star$}

\author{
    Jason Poulos\thanks{\href{mailto:poulos@berkeley.edu}{\nolinkurl{poulos@berkeley.edu}}. SID: 24993379.}
    \hspace{10mm}
    Rafael Valle\thanks{\href{mailto:rafaelvalle@berkeley.com}{\nolinkurl{rafaelvalle@berkeley.com}}. SID: 24090989.}
    \vspace{15mm}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
Researchers analyzing survey data typically choose decision trees or random forests for prediction tasks, largely because missing data and categorical variables are not easy to handle with neural networks. This paper investigates techniques for handling missing data and encoding categorical data such that it is appropriate to neural network classifiers. We experiment on the Adult dataset $N=48,842$, comparing six different imputation strategies, a simple and complex neural network classifier, and a 3x3 parameter grid. We select three cross--validated models to predict on the test data and find the simple neural network trained on data with missing values imputed using random forests yields the lowest generalization error. 
\end{abstract}

\footnotetext[1]{The video presentation can be viewed at \url{https://youtu.be/2bSPE6gzbN8}. The code used for this project is available at \url{https://github.com/jvpoulos/cs289-project}.}

%\linenumbers

%% main text
\section{Introduction} \label{section:Intro}

Missing data is a common problem in survey data in various domains. Several
techniques for data imputation (i.e., replace missing values with plausible ones) and
direct estimation (i.e., all missing data is analyzed using a maximum likelihood
approach) have been proposed ~\cite{de2003prevention}. \\

Random Forests and other ensembles of decision trees are the method of choice for survey data, largely because missing data and categorical variables are not easy to handle with neural networks. We investigate techniques for handling missing data and
encoding categorical data such that it is appropriate to neural network classifiers. We compare six different imputation strategies:  case substitution; mean or median imputation; one--hot; hot deck and cold deck; prediction model; and factor analysis. These strategies are defined in Section \ref{section:techniques}. \\

After briefly reviewing related works in Section~\ref{section:rw}, we experiment using neural networks on benchmark data and compare our results with the state-of-the-art in Section~\ref{section:experiments}. Finally, we draw conclusions in Section~\ref{section:Con}.

\section{Related work}  \label{section:rw}

\subsection{Techniques for handling missing data} \label{section:techniques}
We categorize proposed  imputation methods into six groups listed
below ~\cite{batista2003analysis}:

\begin{description}
\item[Case substitution] One observation with missing data is replaced with
another non-sampled observation.
\item[Summary statistic] Replace the missing data with the mean, median, or mode of
    the feature vector. Using a numerical approach directly is not appropriate for nonordinal categorical data.
\item[One-hot] Create a binary variable to indicate whether or not a specific
    feature is missing. %This technique was suggested by Isabelle Guyon.
\item[Hot deck and cold deck] Compute the K-Nearest Neighbors of the
    observation with missing data and assign the mode of the K-neighbors
    to the missing data. %A similar technique is used in Airbnb's fraud detection
    algorithm.
\item[Prediction Model] Train a prediction model (e.g., random forests) to predict the missing value. %This requires correlation amongst features to exist.
\item[Factor analysis] Perform factor analysis (e.g., principal component analysis (PCA)) on the design
    matrix, project the design matrix onto the first two eigenvectors and
    replace the missing values by the values that might be given by the
    projected design matrix.
\end{description}

\subsection{Neural networks for classification with categorical and
continuous features}  Common techniques for handling categorical data in
neural networks include encoding the categorical values into numeric values
or using binary encoding. These techniques, however, have some drawbacks
including unnecessarily increasing model complexity or feature dimensionality
and not preserving the similarity information embedded between categorical
values ~\cite{hsu2006generalizing}.\\

More elaborate techniques include information theoretic measures
~\cite{wang2008categorical}, training separate output units for
each of the allowed combination of values of the categorical independent
variables ~\cite{brouwer2002feed}, and using distance
hierarchies ~\cite{hsu2006generalizing}. \\

In the case of categorical variables, which by definition have no direct
representation or computation scheme of the distance between its values,
decision trees can be useful because they do not require distance metrics.
However, their training process is slow given a large enough dataset and they
might not be suitable for problems where the decision boundary between classes
described by a second-order polynomial,\footnote{We note, however, that a
property test can be as complex as the data at hand.} for
example ~\cite{fayyad1996data}.

\section{Experiments} \label{section:experiments}

\subsection{Benchmark data set}

We experiment on the Adult dataset from the UCI Machine Learning Repository ~\cite{Lichman2013}. The dataset has $N=48,842$ instances, $2/3$ for training and $1/3$ reserved as a final test set (i.e., $\mathrm{train}=32,561$ and $\mathrm{test}=16,281$). The dataset contains 14 features: 6 continuous and 8 categorical. The prediction task is to determine whether a person makes over \$50,000 a year. 24\% of individuals in the training data make more than this amount. \\

Table \ref{tab:benchmarks} shows the test error rates obtained by the data set donor ~\cite{kohavi1996}. All error rates were obtained after removing samples with missing values. The state--of--the--art is a Naive Bayes classifier that achieves a  14.05\% error rate. \\

\begin{table}[htb]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Algorithm}       & \textbf{Error (\%)} \\ \midrule
1  C4.5                  & 15.54          \\
2  C4.5-auto             & 14.46          \\
3  C4.5 rules            & 14.94          \\
4  Voted ID3 (0.6)       & 15.64          \\
5  Voted ID3 (0.8)       & 16.47          \\
6  T2                    & 16.84          \\
7  1R                    & 19.54          \\
8  NBTree                & 14.10          \\
9  CN2                   & 16.00          \\
10 HOODG                 & 14.82          \\
      \rowcolor{Gray}
11 FSS Naive Bayes       & 14.05          \\
12 IDTM (Decision table) & 14.46          \\
13 Naive-Bayes           & 16.12          \\
14 Nearest-neighbor (1)  & 21.42          \\ \bottomrule
\end{tabular}
\caption{Test set error rates on Adult dataset for various algorithms, obtained after removal of samples with missing values and using the original train/test split. Source: \cite{Lichman2013}.}
\label{tab:benchmarks}
\end{table}

\subsection{Patterns of missing values in Adult dataset}

The Adult dataset has 3,620 (7.4\%) samples containing missing values. Missing values occur in three of the categorical features: \textit{Work class}, \textit{Occupation}, and \textit{Native country}. It is unlikely that these values are missing completely at random (MCAR); it is more likely, and much less desirable that the values are not missing at random (MNAR). Since these data originate from a survey, the missing values may be due to respondents unwilling or unable to provide an answer.  \\

Uncovering patterns of missing values in the dataset will help select strategies for imputing missing values. The histogram (left) in Figure \ref{fig:proportion-missing} shows \textit{Work class} and \textit{Occupation} each have about 5.6\% of missing values, and \textit{Native country} has about 1.7\% missing values. The aggregation plot (right) shows 5.5\% of samples are missing values for both \textit{Work class} and \textit{Occupation}. Less than 2\% of samples are missing just \textit{Native country} and less than 1\% are missing all three features.\\

Figure \ref{fig:barplot-missing} shows the frequency of observed categories and missing values for \textit{Work class} and \textit{Occupation}. Each stacked column shows the proportion of missing values in the other feature and \textit{Native country} for each category. The plot shows the missing values are not MCAR: individuals working in the private sector, for instance, are more likely to have missing values than those individuals in other work classes. However, missing values tend to be evenly distributed across occupational categories. 

\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/proportion-missing.pdf}
   \caption{Histogram of proportion of missing values in each feature (Left) of Adult training set and aggregation plot of all existing combinations of missing and non-missing values in the samples (Right).}
   \label{fig:proportion-missing}
\end{figure*}

\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/barplot-missing.pdf}
   \caption{Barplot of proportion of observed and missing values of \textit{Work class} and \textit{Occupation} in Adult dataset.}
   \label{fig:barplot-missing}
\end{figure*}

\subsection{Preprocessing}

We preprocess the training and test data as follows:

\begin{enumerate}
\item Drop the string feature \texttt{education} because it contains identical information as its numeric counterpart \texttt{education.num}.
\item Binarize the categorical variables.
\item Implement imputation technique. When replacing the missing data with the mean, median, or mode of
    the feature vector, the summary statistic is computed from the training data, not from the test data.
\item Standardize each feature to midrange 0 and range 2 (i.e., minimum -1 and maximum 1). We use the training set values for range and midrange to standardize test set features.
\end{enumerate}

\subsection{Model selection}

We implement two neural network classifiers: a simple model and a complex model. The complex model uses two hidden layers, both with the same size of hidden nodes, which is computed using the formula $N_h = \frac{N_s}{(\alpha * (N_i + N_o)}$, where the number of hidden nodes $N_h$ is a function of the number of training examples $N_s$, a scaling parameter $\alpha$, the number of input neurons $N_i$, and the number of output neurons $N_s$. The complex model uses root-mean-square gradient scaling for the update rule, while the simple model uses one hidden layer and stochastic gradient descent for the update rule. Both models use a cross--entropy cost function and weights initialized randomly using Gaussian distribution and scaled by a factor of $10^{-2}$. 

We use two layers of cross--validation for selecting model parameters: grid search and $K$--fold cross validation. We perform an exhaustive search on a grid of parameter values composed of $\alpha = \{1,4,9\}$ learning rate $\gamma = \{10^{-1}, 10^{-2}, 10^{-3}\}$, and $\mathrm{mini-batch\, size} = \{32, 512, 4096\}$. For each $3!*3 = 18$ parameter combinations, we perform $K$--fold cross--validation on $k=3$ folds. We evaluate the models based on the average error rate across folds and also record average cost and average computing time across folds.  

We train both simple and complex classifiers on data with missing values imputed using most of the techniques described in Section \ref{section:techniques} and on data with instances with missing values removed. Figure \ref{fig:predicted-simple-2d} provides a visual example of the results of the simple neural network on training data with missing values imputed using random forests. Table \ref{tab:err-rates} reports the models with the lowest cross--validated error rate. The simple neural network outperforms the complex classifier in most cases. We find that omitting instances with missing values yields a lower error rate on the training data than all of the imputation methods. The difference between imputation methods in terms of accuracy is minimal. 

\begin{table*}[htbp]
\begin{center}
\begin{tabular}{llllllll}
\textbf{Imputation method} & \textbf{Model type} & \textbf{$\alpha$} & \textbf{$\gamma$} & \textbf{Batch size} & \textbf{Error rate} & \textbf{Cost} & \textbf{Time (min.)} \\
\hline
      \rowcolor{Gray}
Remove instances with missing values & Simple & 9 & 0.1 & 32 & 0.1406 & 0.1525 & 3.7 \\
Factor analysis (PCA)  & Simple & 4 & 0.1 & 32 & 0.1411 & 0.2487 & 8.3667 \\
      \rowcolor{Gray}
Prediction model (random forests) & Simple & 4 & 0.1 & 32 & 0.1413 & 0.2056 & 6.7 \\
      \rowcolor{Gray}
Summary statistic (mode) & Simple & 9 & 0.1 & 32 & 0.1415 & 0.1829 & 4.2667 \\
Case substitution & Simple & 1 & 0.1 & 32 & 0.1417 & 0.2189 & 6.8 \\
Prediction model  (random forests) & Complex & 1 & 0.1 & 32 & 0.1426 & 0.2919 & 9.9 \\
Factor analysis (PCA) & Complex & 1 & 0.01 & 32 & 0.143 & 0.3175 & 11 \\
Remove instances with missing values & Complex & 1 & 0.1 & 32 & 0.1439 & 0.1778 & 8.5 \\
Summary statistic (median) & Simple & 4 & 0.1 & 32 & 0.1446 & 0.1924 & - \\
Summary statistic (mean) & Simple & 4 & 0.1 & 32 & 0.1453 & 0.1915 & - \\
Summary statistic (mean) & Complex & 1 & 0.1 & 32 & 0.1593 & 0.3118 & - \\
Summary statistic  (median) & Complex & 1 & 0.01 & 32 & 0.1595 & 0.3564 & - \\
\hline
\end{tabular}
\end{center}
\caption{Performance of models selected on the basis of cross--validated error rate on the training data. \texttt{Imputation method} is how missing values in the training data are imputed; \texttt{Model type} is the type of neural network classifier used; \texttt{$\alpha$} is the scaling factor used to determine the number of hidden neurons in the neural network; \texttt{$\gamma$} is the learning rate; \texttt{Batch size} is the size of the batch; \texttt{Error rate} is the mean 3-fold cross--validated error rate on the training data;  \texttt{Cost} is the mean cross--entropy cost across folds; \texttt{Time} is the mean training time across folds. }
\label{tab:err-rates}
\end{table*}


\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/predicted-simple-2d.png}
   \caption{Performance of simple neural network on training data with missing values imputed using random forests: 3-fold cross--validated error rate versus $\alpha$ (x--axis) and $\gamma$ (colors). See Table \ref{tab:err-rates} for definitions.}
   \label{fig:predicted-simple-2d}
\end{figure*}

\subsection{Model assessment}

We select the three highlighted models in Table \ref{tab:err-rates} to train on the entire training set and then fit each model on the test features. We handle missing values in the test features in the same manner as the training features. The simple neural network trained on data with missing values imputed using random forests yields the highest accuracy (16.63\% error rate), followed by mode imputation (16.84\%), and missing values removed (18.59\%). 

\section{Conclusion} \label{section:Con}

Neural networks have become a popular machine learning algorithm in many domains, in part due to the ability of neural networks to ``learn'' how to engineer features.  However, researchers analyzing survey data typically choose decision trees or random forests for prediction tasks because missing data and categorical variables are not easy to handle with neural networks. This paper investigates techniques for handling missing data and encoding categorical data such that it is appropriate to neural network classifiers. We compare six different imputation strategies, a simple and complex neural network classifier, and a 3x3 parameter grid. 

We use the Adult dataset for benchmarking because it has a mixture of continuous and categorical variables and has under 10\% of the instances containing missing values. Removing instances with missing values instead of imputing the missing values actually yields the highest cross--validated accuracy on the training set. This finding suggest that the instances with missing values or the features that contain missing values (i.e., \textit{occupation}, \textit{work class}, and \textit{native country}) do not contribute meaningful information for the prediction task. Another interpretation is that there is not enough missing values in the training data for imputation to make a difference.

However, we find that two of the imputation methods --- prediction using random forests and replacing the missing values with column modes --- both yield lower generalization error than no imputation. Our lowest test error is within 3\% of the state--of--the--art, which uses Naive Bayes and removes data with missing values. 

For future work, we will explore the relevance of the features with missing data and the amount of missing data for this particular prediction task. 
%\section*{Acknowledgments}

{\small
\bibliographystyle{ieee}
\bibliography{refs}
}

\end{document}
