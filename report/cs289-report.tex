\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{booktabs}
\usepackage{cvpr}
\usepackage{graphicx}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{hyperref}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\thefootnote}{$\star$}

\cvprfinalcopy % *** Uncomment this line for the final submission

\usepackage{footmisc} % Daggers for author notes
\DefineFNsymbols{mySymbols}{{\ensuremath\dagger}{\ensuremath\ddagger}\S\P
   *{**}{\ensuremath{\dagger\dagger}}{\ensuremath{\ddagger\ddagger}}}
\setfnsymbol{mySymbols}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Methods for handling missing and categorical data for classification with neural
networks$^\star$}

\author{
    Jason Poulos\thanks{\href{mailto:poulos@berkeley.edu}{\nolinkurl{poulos@berkeley.edu}}. SID: 24993379.}
    \hspace{10mm}
    Rafael Valle\thanks{\href{mailto:rafaelvalle@berkeley.com}{\nolinkurl{rafaelvalle@berkeley.com}}. SID: 24090989.}
    \vspace{15mm}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
Abstract here...
\end{abstract}

\footnotetext[1]{The video presentation can be viewed at \url{youtube.com/foo}. The code used for this project is available at \url{https://github.com/jvpoulos/cs289-project}.}

%\linenumbers

%% main text
\section{Introduction} \label{section:Intro}

Missing data is a common problem in survey data in various domains. Several
techniques for data imputation (i.e., replace missing values with plausible ones) and
direct estimation (i.e., all missing data is analyzed using a maximum likelihood
approach) have been proposed ~\cite{de2003prevention}. \\

Random Forest and other ensembles of decision trees are the method of choice for survey data, largely because missing data and categorical variables are not easy to handle with neural networks. We investigate techniques for handling missing data and
encoding categorical data such that it is appropriate to neural network classifiers. We compare six different imputation strategies:  case substitution; mean or median imputation; one--hot; hot deck and cold deck; prediction model; and factor analysis. These strategies are defined in Section \ref{section:techniques}. \\

After briefly reviewing related works in Section~\ref{section:rw}, we experiment using neural networks on benchmark data and compare our results with the state-of-the-art in Section~\ref{section:experiments}. Finally, we draw conclusions in Section~\ref{section:Con}.

\section{Related work}  \label{section:rw}

\subsection{Techniques for handling missing data} \label{section:techniques}
We divide proposed  imputation methods into six groups listed
below ~\cite{batista2003analysis}:

\begin{description}
\item[Case substitution] One observation with missing data is replaced with
another non-sampled observation.
\item[Summary statistic] Replace the missing data with the mean, median, or mode of
    the feature vector. Using a numerical approach directly is not appropriate for nonordinal categorical data.
\item[One-hot] Create a binary variable to indicate whether or not a specific
    feature is missing. %This technique was suggested by Isabelle Guyon.
\item[Hot deck and cold deck] Compute the K-Nearest Neighbors of the
    observation with missing data and assign the mode of the K-neighbors
    to the missing data. %A similar technique is used in Airbnb's fraud detection
    algorithm.
\item[Prediction Model] Train a single prediction model (e.g., random forests) or ensemble of models to predict the missing value. %This requires correlation amongst features to exist.
\item[Factor analysis] Perform principal component analysis (PCA) on the design
    matrix, project the design matrix onto the first two eigenvectors and
    replace the missing values by the values that might be given by the
    projected design matrix.
\end{description}

\subsection{Neural networks for classification with categorical and
continuous features}  Common techniques for handling categorical data in
neural networks include encoding the categorical values into numeric values
or using binary encoding. These techniques, however, have some drawbacks
including unnecessarily increasing model complexity or feature dimensionality
and not preserving the similarity information embedded between categorical
values ~\cite{hsu2006generalizing}.\\

More elaborate techniques include information theoretic measures
~\cite{wang2008categorical}, training separate output units for
each of the allowed combination of values of the categorical independent
variables ~\cite{brouwer2002feed}, and using distance
hierarchies ~\cite{hsu2006generalizing}.

In the case of categorical variables, which by definition have no direct
representation or computation scheme of the distance between its values,
decision trees can be useful because they do not require distance metrics.
However, their training process is slow given a large enough dataset and they
might not be suitable for problems where the decision boundary between classes
described by a second-order polynomial,\footnote{We note, however, that a
property test can be as complex as the data at hand.} for
example ~\cite{fayyad1996data}. \\

\section{Experiments} \label{section:experiments}

\subsection{Benchmark data set}

We experiment with the Adult dataset from the UCI Machine Learning Repository ~\cite{Lichman2013}. The dataset has 48,842 instances, $2/3$ for training and $1/3$ reserved as a final test set (i.e., $\mathrm{train}=32,561$ and $\mathrm{test}=16,281$). The dataset contains 14 features: 6 continuous and 8 categorical. The prediction task is to determine whether a person makes over \$50,000 a year. 24\% of individuals in the training data make more than this amount. \\

Table \ref{tab:benchmarks} shows the test error rates obtained by the data set donor ~\cite{kohavi1996}. All error rates were obtained after removing samples with missing values. The state--of--the--art is a Naive Bayes classifier that achieves a  14.05\% error rate. \\

\begin{table}[htb]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Algorithm}       & \textbf{Error (\%)} \\ \midrule
1  C4.5                  & 15.54          \\
2  C4.5-auto             & 14.46          \\
3  C4.5 rules            & 14.94          \\
4  Voted ID3 (0.6)       & 15.64          \\
5  Voted ID3 (0.8)       & 16.47          \\
6  T2                    & 16.84          \\
7  1R                    & 19.54          \\
8  NBTree                & 14.10          \\
9  CN2                   & 16.00          \\
10 HOODG                 & 14.82          \\
11 FSS Naive Bayes       & 14.05          \\
12 IDTM (Decision table) & 14.46          \\
13 Naive-Bayes           & 16.12          \\
14 Nearest-neighbor (1)  & 21.42          \\ \bottomrule
\end{tabular}
\caption{Test set error rates on Adult dataset for various algorithms, obtained after removal of samples with missing values and using the original train/test split. Source: \cite{Lichman2013}.}
\label{tab:benchmarks}
\end{table}

\subsection{Patterns of missing values in Adult dataset}

The Adult dataset has 3,620 (7.4\%) samples containing missing values. Missing values occur in three of the categorical features: \textit{Work class}, \textit{Occupation}, and \textit{Native country}. It is unlikely that these values are missing completely at random (MCAR); it is more likely, and much less desirable that the values are not missing at random (MNAR). Since these data originate from a survey, the missing values may be due to respondents unwilling or unable to provide an answer.  \\

Uncovering patterns of missing values in the dataset will help select strategies for imputing missing values. The histogram (left) in Figure \ref{fig:proportion-missing} shows \textit{Work class} and \textit{Occupation} each have about 5.6\% of missing values, and \textit{Native country} has about 1.7\% missing values. The aggregation plot (right) shows 5.5\% of samples are missing values for both \textit{Work class} and \textit{Occupation}. Less than 2\% of samples are missing just \textit{Native country} and less than 1\% are missing all three features.\\

Figure \ref{fig:barplot-missing} shows the frequency of observed categories and missing values for \textit{Work class} and \textit{Occupation}. Each stacked column shows the proportion of missing values in the other feature and \textit{Native country} for each category. The plot shows the missing values are not MCAR: individuals working in the private sector, for instance, are more likely to have missing values than those individuals in other work classes. However, missing values tend to be evenly distributed across occupational categories. 

\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/proportion-missing.pdf}
   \caption{Histogram of proportion of missing values in each feature (Left) of Adult training set and aggregation plot of all existing combinations of missing and non-missing values in the samples (Right).}
   \label{fig:proportion-missing}
\end{figure*}

\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/barplot-missing.pdf}
   \caption{Barplot of proportion of observed and missing values of \textit{Work class} and \textit{Occupation} in Adult dataset.}
   \label{fig:barplot-missing}
\end{figure*}

\subsection{Preprocessing}

We preprocess the training and test data as follows:

\begin{enumerate}
\item Drop the string feature \texttt{education} because it contains identical information as its numeric counterpart \texttt{education.num}.
\item Binarize the categorical variables.
\item Implement imputation technique. When replacing the missing data with the mean, median, or mode of
    the feature vector, the summary statistic is computed from the training data, not from the test data.
\item Standardize each feature to midrange 0 and range 2 (i.e., minimum -1 and maximum 1). We use the training set values for range and midrange to standardize test set features.
\end{enumerate}

\subsection{Model selection}

We implement two neural network classifiers: a simple model and a complex model. The complex model uses two hidden layers, both with the same size of hidden notes, which is computed using the formula, and root-mean-square gradient scaling for the update rule. The simple model uses one hidden layer and stochastic gradient descent for the update rule. Both models use a cross--entropy cost function and weights initialized randomly using Gaussian distribution and scaled by a factor of $10^{-2}$. 

formula 

grid search 

k-fold cv

Table \ref{tab:err-rates}

Figure \ref{fig:barplot-missing}

\begin{table*}[htbp]
\begin{center}
\begin{tabular}{llllllll}
\textbf{Imputation method} & \textbf{Model type} & \textbf{$\alpha$} & \textbf{$\gamma$} & \textbf{Batch size} & \textbf{Error rate} & \textbf{Cost} & \textbf{Time (min.)} \\
\hline
Drop & Simple & 9 & 0.1 & 32 & 0.1406 & 0.1525 & 3.7 \\
PCA & Simple & 4 & 0.1 & 32 & 0.1411 & 0.2487 & 8.3667 \\
Predicted & Simple & 4 & 0.1 & 32 & 0.1413 & 0.2056 & 6.7 \\
Mode & Simple & 9 & 0.1 & 32 & 0.1415 & 0.1829 & 4.2667 \\
Replace & Simple & 1 & 0.1 & 32 & 0.1417 & 0.2189 & 6.8 \\
Predicted & Complex & 1 & 0.1 & 32 & 0.1426 & 0.2919 & 9.9 \\
PCA & Complex & 1 & 0.01 & 32 & 0.143 & 0.3175 & 11 \\
Drop & Complex & 1 & 0.1 & 32 & 0.1439 & 0.1778 & 8.5 \\
Median & Simple & 4 & 0.1 & 32 & 0.1446 & 0.1924 & - \\
Mean & Simple & 4 & 0.1 & 32 & 0.1453 & 0.1915 & - \\
Mean & Complex & 1 & 0.1 & 32 & 0.1593 & 0.3118 & - \\
Median & Complex & 1 & 0.01 & 32 & 0.1595 & 0.3564 & - \\
\hline
\end{tabular}
\end{center}
\caption{Performance of models selected on the basis of cross--validated error rate on the training data. \texttt{Imputation method}is how missing values in the training data are imputed; \texttt{Model type} is the type of neural network classifier used; \texttt{$\alpha$} is the scaling factor used to determine the number of hidden neurons in the neural network; \texttt{$\gamma$} is the learning rate; \texttt{Batch size} is the size of the batch; \texttt{Error rate} is the mean 3-fold cross--validated error rate on the training data;  \texttt{Cost} is the mean cross--entropy cost across folds; \texttt{Time} is the mean computational time across folds. }
\label{tab:err-rates}
\end{table*}


\begin{figure*}[htbp] 
   \centering
   \includegraphics[width=0.8\textwidth]{./figure/predicted-simple-2d.png}
   \caption{Performance of simple neural network on training data with missing values imputed using random forests: 3-fold cross--validated error rate versus $\alpha$ (x--axis) and $\gamma$ (colors). See Table \ref{tab:err-rates} for definitions.}
   \label{fig:barplot-missing}
\end{figure*}

\subsection{Model assessment}

Mode: 0.1684 (1 epoch)
Drop: 0.1859 (1 epoch)
Predict: 0.1663 (1 epoch) 

\section{Conclusions} \label{section:Con}

%\section*{Acknowledgments}

{\small
\bibliographystyle{ieee}
\bibliography{refs}
}

\end{document}
